{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35f4319d-d996-4f43-9b7b-98efcaa08fda",
   "metadata": {},
   "source": [
    "### **`check_envs_registration.ipynb`**\n",
    "\n",
    "\n",
    "This notebook verifies the successful registration of all custom `LLECBuildingGym` environments and performs basic environment interaction tests.  \n",
    "It includes:\n",
    "- Import validation and environment listing  \n",
    "- Basic reset and step checks for selected environments  \n",
    "- Reward consistency validation  \n",
    "- Gymnasium environment compliance check (`check_env`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "695212fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /home/iai/ii6824/llec_env/bin/python\n",
      "  python3           /hkfs/home/haicore/iai/ii6824/llec_env/share/jupyter/kernels/python3\n",
      "llec_building_gym path: /hkfs/home/haicore/iai/ii6824/LLECBuildingGym/llec_building_gym/__init__.py\n",
      "Module 'llec_building_gym' successfully loaded.\n",
      "\n",
      "Registered LLEC environments:\n",
      "  LLEC-HeatPumpHouse-1R1C-Combined-v0\n",
      "  LLEC-HeatPumpHouse-1R1C-Temperature-v0\n",
      "\n",
      "Total found: 2 LLEC environments\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "\n",
    "print(\"Python executable:\", sys.executable)\n",
    "# Display all available Jupyter kernels\n",
    "!jupyter kernelspec list | grep llec_env\n",
    "\n",
    "# Attempt to the LLECBuildingGym module, which registers custom environments via `register()`\n",
    "try:\n",
    "    import llec_building_gym  # Triggers registration on llec_building_gym/__init__.py and registers environments\n",
    "\n",
    "    print(\"llec_building_gym path:\", llec_building_gym.__file__)\n",
    "    print(\"Module 'llec_building_gym' successfully loaded.\")\n",
    "except ImportError:\n",
    "    print(\"Module 'llec_building_gym' could not be loaded.\")\n",
    "    print(\"Please install it using: pip install -e .\")\n",
    "else:\n",
    "    print(\"\\nRegistered LLEC environments:\")\n",
    "    # List all environments containing 'LLEC' in their ID\n",
    "    custom_envs = [\n",
    "        env_id for env_id in sorted(gym.envs.registry.keys()) if \"LLEC\" in env_id\n",
    "    ]\n",
    "    if not custom_envs:\n",
    "        print(\"No LLEC environments found.\")\n",
    "    else:\n",
    "        for env_id in custom_envs:\n",
    "            print(f\"  {env_id}\")\n",
    "        print(f\"\\nTotal found: {len(custom_envs)} LLEC environments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aeb958c6-12ec-479f-af77-e987326ebb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 21:08:42,020 - INFO - [EnvID:23409952903760] schedule=synthetic-temp-class class=Cold | Tmin=-1.3degC  Tmax=9.0degC  φ=0.137  seed=6184\n",
      "2025-11-20 21:08:42,029 - INFO - [EnvID:23409952903760] schedule=synthetic-temp-class class=Cold | Tmin=-1.3degC  Tmax=9.0degC  φ=0.137  seed=8392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hkfs/home/haicore/iai/ii6824/LLECBuildingGym/llec_building_gym/__init__.py\n",
      "Observation Space: Box(-inf, inf, (1,), float32)\n",
      "Action Space: Box(-1.0, 1.0, (1,), float32)\n",
      "Initial observation: [1.8914707]\n"
     ]
    }
   ],
   "source": [
    "print(llec_building_gym.__file__)\n",
    "\n",
    "# Choose one of the available environments below:\n",
    "env = gym.make(\"LLEC-HeatPumpHouse-1R1C-Temperature-v0\")\n",
    "# env = gym.make(\"LLEC-HeatPumpHouse-1R1C-Combined-v0\")\n",
    "\n",
    "# Print observation and action space information\n",
    "print(\"Observation Space:\", env.observation_space)\n",
    "print(\"Action Space:\", env.action_space)\n",
    "\n",
    "# Reset the environment and display the initial observation\n",
    "obs, info = env.reset()\n",
    "print(\"Initial observation:\", obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5d93c77-aeb1-491c-9082-ed23eee7e8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Registered Gym Environments ===\n",
      "\n",
      "Environment 'LLEC-HeatPumpHouse-1R1C-Temperature-v0' is successfully registered.\n"
     ]
    }
   ],
   "source": [
    "# Print all registered environments\n",
    "print(\"=== Registered Gym Environments ===\")\n",
    "env_list = sorted(gym.envs.registry.keys())\n",
    "\n",
    "# Check if the desired environment is registered\n",
    "env_name = \"LLEC-HeatPumpHouse-1R1C-Temperature-v0\"\n",
    "if env_name in env_list:\n",
    "    print(f\"\\nEnvironment '{env_name}' is successfully registered.\")\n",
    "else:\n",
    "    print(\n",
    "        f\"\\nEnvironment '{env_name}' is not registered. Please check your setup or registration logic.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9999cd2-cb40-4d96-b3d3-057b8fadc9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 21:08:42,117 - INFO - [EnvID:23405731434208] schedule=synthetic-temp-class class=Cold | Tmin=-1.3degC  Tmax=9.0degC  φ=0.137  seed=6184\n",
      "2025-11-20 21:08:42,145 - INFO - [EnvID:23405731434208] schedule=synthetic-temp-class class=Cold | Tmin=-1.3degC  Tmax=9.0degC  φ=0.137  seed=6184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 288 steps.\n",
      "Final indoor temperature: 3.47°C\n",
      "Final observation: [-18.820786]\n",
      "Final observation length: 1\n",
      "Final reward: 0.00\n"
     ]
    }
   ],
   "source": [
    "from llec_building_gym import BaseBuildingGym  # Adjust the path if necessary\n",
    "\n",
    "# Instantiate the environment\n",
    "env = BaseBuildingGym(energy_price_path=\"../data/price_data_2025.csv\")\n",
    "obs, _ = env.reset()\n",
    "step_count = 0\n",
    "\n",
    "# Simulate one full episode using random actions\n",
    "while True:\n",
    "    action = env.action_space.sample()  # Sample a random action\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    step_count += 1\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "\n",
    "# Print episode summary\n",
    "print(f\"Episode finished after {step_count} steps.\")\n",
    "print(f\"Final indoor temperature: {env.building.T_in:.2f}°C\")\n",
    "print(f\"Final observation: {obs}\")\n",
    "print(f\"Final observation length: {len(obs)}\")\n",
    "print(f\"Final reward: {reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b380030-30d0-48d8-a84f-d040a6cb03e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 21:08:42,297 - INFO - [EnvID:23405731433200] schedule=synthetic-temp-class class=Cold | Tmin=-1.3degC  Tmax=9.0degC  φ=0.137  seed=6184\n",
      "2025-11-20 21:08:42,325 - INFO - [EnvID:23405731433200] schedule=synthetic-temp-class class=Very cold | Tmin=-6.0degC  Tmax=3.9degC  φ=0.184  seed=42\n",
      "2025-11-20 21:08:42,380 - INFO - [EnvID:23405731448576] schedule=synthetic-temp-class class=Cold | Tmin=-1.3degC  Tmax=9.0degC  φ=0.137  seed=6184\n",
      "2025-11-20 21:08:42,408 - INFO - [EnvID:23405731448576] schedule=synthetic-temp-class class=Very cold | Tmin=-6.0degC  Tmax=3.9degC  φ=0.184  seed=42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing: LLEC-HeatPumpHouse-1R1C-Combined-v0 ===\n",
      "Initial observation: [0.8960016]\n",
      "\n",
      "Step 1\n",
      "  Action: [0.703522]\n",
      "  Observation: [6.542649]\n",
      "  Reward: -0.1362\n",
      "  Terminated: False, Truncated: False\n",
      "  Info:\n",
      "    temp_deviation: 6.0859\n",
      "    action: [0.703522]\n",
      "    T_out: -1.9394\n",
      "    Q_HP_Max: 1500\n",
      "    controlled_Q_HP: 1055.2830\n",
      "    P_HP_el: 1055.2830\n",
      "    E_HP_el_Wh: 87.9403\n",
      "    cop_used: 1.0000\n",
      "    reward: -0.1362\n",
      "    reward_temperature: 0.0023\n",
      "    reward_economic: -0.1385\n",
      "    reward_temperature_norm: 0.0023\n",
      "    reward_economic_norm: -0.1385\n",
      "    history_temp_deviations: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0859294400123645]\n",
      "\n",
      "Step 2\n",
      "  Action: [0.14700723]\n",
      "  Observation: [5.843391]\n",
      "  Reward: -0.0241\n",
      "  Terminated: False, Truncated: False\n",
      "  Info:\n",
      "    temp_deviation: 5.3410\n",
      "    action: [0.14700723]\n",
      "    T_out: -1.8334\n",
      "    Q_HP_Max: 1500\n",
      "    controlled_Q_HP: 220.5108\n",
      "    P_HP_el: 220.5108\n",
      "    E_HP_el_Wh: 106.3162\n",
      "    cop_used: 1.0000\n",
      "    reward: -0.0241\n",
      "    reward_temperature: 0.0048\n",
      "    reward_economic: -0.0289\n",
      "    reward_temperature_norm: 0.0048\n",
      "    reward_economic_norm: -0.0289\n",
      "    history_temp_deviations: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0859294400123645, 5.341032282338347]\n",
      "\n",
      "Step 3\n",
      "  Action: [0.5578855]\n",
      "  Observation: [3.2170448]\n",
      "  Reward: -0.0914\n",
      "  Terminated: False, Truncated: False\n",
      "  Info:\n",
      "    temp_deviation: 3.9968\n",
      "    action: [0.5578855]\n",
      "    T_out: -1.7270\n",
      "    Q_HP_Max: 1500\n",
      "    controlled_Q_HP: 836.8283\n",
      "    P_HP_el: 836.8283\n",
      "    E_HP_el_Wh: 176.0518\n",
      "    cop_used: 1.0000\n",
      "    reward: -0.0914\n",
      "    reward_temperature: 0.0184\n",
      "    reward_economic: -0.1098\n",
      "    reward_temperature_norm: 0.0184\n",
      "    reward_economic_norm: -0.1098\n",
      "    history_temp_deviations: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0859294400123645, 5.341032282338347, 3.996842989275244]\n",
      "\n",
      "=== Testing: LLEC-HeatPumpHouse-1R1C-Temperature-v0 ===\n",
      "Initial observation: [0.8960016]\n",
      "\n",
      "Step 1\n",
      "  Action: [-0.13541049]\n",
      "  Observation: [7.895484]\n",
      "  Reward: 0.0006\n",
      "  Terminated: False, Truncated: False\n",
      "  Info:\n",
      "    temp_deviation: 7.3443\n",
      "    action: [-0.13541049]\n",
      "    T_out: -1.9394\n",
      "    Q_HP_Max: 1500\n",
      "    controlled_Q_HP: -203.1157\n",
      "    P_HP_el: 203.1157\n",
      "    E_HP_el_Wh: 16.9263\n",
      "    cop_used: 1.0000\n",
      "    reward: 0.0006\n",
      "    reward_temperature: 0.0006\n",
      "    reward_economic: -0.0267\n",
      "    reward_temperature_norm: 0.0006\n",
      "    reward_economic_norm: -0.0267\n",
      "    history_temp_deviations: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.344328211298375]\n",
      "\n",
      "Step 2\n",
      "  Action: [0.62308735]\n",
      "  Observation: [6.4113274]\n",
      "  Reward: 0.0029\n",
      "  Terminated: False, Truncated: False\n",
      "  Info:\n",
      "    temp_deviation: 5.8601\n",
      "    action: [0.62308735]\n",
      "    T_out: -1.8334\n",
      "    Q_HP_Max: 1500\n",
      "    controlled_Q_HP: 934.6310\n",
      "    P_HP_el: 934.6310\n",
      "    E_HP_el_Wh: 94.8122\n",
      "    cop_used: 1.0000\n",
      "    reward: 0.0029\n",
      "    reward_temperature: 0.0029\n",
      "    reward_economic: -0.1227\n",
      "    reward_temperature_norm: 0.0029\n",
      "    reward_economic_norm: -0.1227\n",
      "    history_temp_deviations: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.344328211298375, 5.860142898783888]\n",
      "\n",
      "Step 3\n",
      "  Action: [0.6656338]\n",
      "  Observation: [3.4964292]\n",
      "  Reward: 0.0130\n",
      "  Terminated: False, Truncated: False\n",
      "  Info:\n",
      "    temp_deviation: 4.3439\n",
      "    action: [0.6656338]\n",
      "    T_out: -1.7270\n",
      "    Q_HP_Max: 1500\n",
      "    controlled_Q_HP: 998.4507\n",
      "    P_HP_el: 998.4507\n",
      "    E_HP_el_Wh: 178.0165\n",
      "    cop_used: 1.0000\n",
      "    reward: 0.0130\n",
      "    reward_temperature: 0.0130\n",
      "    reward_economic: -0.1310\n",
      "    reward_temperature_norm: 0.0130\n",
      "    reward_economic_norm: -0.1310\n",
      "    history_temp_deviations: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.344328211298375, 5.860142898783888, 4.34394898833969]\n"
     ]
    }
   ],
   "source": [
    "# List of all registered environment IDs to test\n",
    "registered_envs = [\n",
    "    \"LLEC-HeatPumpHouse-1R1C-Combined-v0\",\n",
    "    \"LLEC-HeatPumpHouse-1R1C-Temperature-v0\",\n",
    "]\n",
    "\n",
    "\n",
    "def test_env(env_id, n_steps=3):\n",
    "    print(f\"\\n=== Testing: {env_id} ===\")\n",
    "    try:\n",
    "        env = gym.make(env_id, energy_price_path=\"../data/price_data_2025.csv\")\n",
    "        obs, info = env.reset(seed=42)\n",
    "        print(f\"Initial observation: {obs}\")\n",
    "\n",
    "        for step in range(n_steps):\n",
    "            action = env.action_space.sample()\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "            print(f\"\\nStep {step + 1}\")\n",
    "            print(f\"  Action: {action}\")\n",
    "            print(f\"  Observation: {obs}\")\n",
    "            print(f\"  Reward: {reward:.4f}\")\n",
    "            print(f\"  Terminated: {terminated}, Truncated: {truncated}\")\n",
    "            print(f\"  Info:\")\n",
    "            for k, v in info.items():\n",
    "                if isinstance(v, float):\n",
    "                    print(f\"    {k}: {v:.4f}\")\n",
    "                else:\n",
    "                    print(f\"    {k}: {v}\")\n",
    "\n",
    "            # Optional: Reward consistency check\n",
    "            if \"reward_temperature\" in info and \"reward_energy\" in info:\n",
    "                reward_check = info[\"reward_temperature\"] + info[\"reward_energy\"]\n",
    "                diff = abs(reward - reward_check)\n",
    "                status = \"ok\" if diff <= 1e-3 else \"(!)\"\n",
    "                print(f\"    Reward consistency check: Δ = {diff:.6f} [{status}]\")\n",
    "\n",
    "            if terminated or truncated:\n",
    "                print(\"  Episode ended early.\")\n",
    "                break\n",
    "\n",
    "        env.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error testing {env_id}: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for env_id in registered_envs:\n",
    "        test_env(env_id, n_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0060c751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 21:08:42,473 - INFO - [EnvID:23405731441776] schedule=synthetic-temp-class class=Cold | Tmin=-1.3degC  Tmax=9.0degC  φ=0.137  seed=6184\n",
      "2025-11-20 21:08:42,502 - INFO - [EnvID:23405731441776] schedule=synthetic-temp-class class=Hot | Tmin=19.5degC  Tmax=31.4degC  φ=-0.094  seed=0\n",
      "2025-11-20 21:08:42,529 - INFO - [EnvID:23405731441776] schedule=synthetic-temp-class class=Cold | Tmin=-1.3degC  Tmax=9.0degC  φ=0.137  seed=6184\n",
      "2025-11-20 21:08:42,556 - INFO - [EnvID:23405731441776] schedule=synthetic-temp-class class=Cold | Tmin=-1.3degC  Tmax=9.0degC  φ=0.137  seed=6184\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "from llec_building_gym import BaseBuildingGym  # Adjust the import path if necessary\n",
    "\n",
    "# Create an instance of your custom environment\n",
    "env = BaseBuildingGym(energy_price_path=\"../data/price_data_2025.csv\")\n",
    "\n",
    "# Run the environment check to validate compatibility with Stable Baselines3\n",
    "check_env(env, warn=True, skip_render_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9740cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment check completed successfully in `check_envs_registration.ipynb`. The environment is compatible with Stable Baselines3.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Environment check completed successfully in `check_envs_registration.ipynb`. The environment is compatible with Stable Baselines3.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llec_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
